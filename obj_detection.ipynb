{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First let's look at the dataset\n",
    "\n",
    "## And try to visualize the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# my tool box for pytorch\n",
    "from p3self.matchbox import *\n",
    "from constant import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118287\r\n"
     ]
    }
   ],
   "source": [
    "%ls {IMG}|wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.text as text\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "os.system(\"mkdir -p /data/bbsample\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image table, with image url , image id, yup , that's all we need now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coco_url</th>\n",
       "      <th>date_captured</th>\n",
       "      <th>file_name</th>\n",
       "      <th>flickr_url</th>\n",
       "      <th>height</th>\n",
       "      <th>id</th>\n",
       "      <th>license</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "      <td>2013-11-14 11:18:45</td>\n",
       "      <td>000000391895.jpg</td>\n",
       "      <td>http://farm9.staticflickr.com/8186/8119368305_...</td>\n",
       "      <td>360</td>\n",
       "      <td>391895</td>\n",
       "      <td>3</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "      <td>2013-11-14 11:38:44</td>\n",
       "      <td>000000522418.jpg</td>\n",
       "      <td>http://farm1.staticflickr.com/1/127244861_ab0c...</td>\n",
       "      <td>480</td>\n",
       "      <td>522418</td>\n",
       "      <td>4</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "      <td>2013-11-14 12:36:29</td>\n",
       "      <td>000000184613.jpg</td>\n",
       "      <td>http://farm3.staticflickr.com/2169/2118578392_...</td>\n",
       "      <td>336</td>\n",
       "      <td>184613</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "      <td>2013-11-14 13:02:53</td>\n",
       "      <td>000000318219.jpg</td>\n",
       "      <td>http://farm5.staticflickr.com/4125/5094763076_...</td>\n",
       "      <td>640</td>\n",
       "      <td>318219</td>\n",
       "      <td>3</td>\n",
       "      <td>556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://images.cocodataset.org/train2017/000000...</td>\n",
       "      <td>2013-11-14 16:03:19</td>\n",
       "      <td>000000554625.jpg</td>\n",
       "      <td>http://farm5.staticflickr.com/4086/5094162993_...</td>\n",
       "      <td>640</td>\n",
       "      <td>554625</td>\n",
       "      <td>3</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            coco_url        date_captured  \\\n",
       "0  http://images.cocodataset.org/train2017/000000...  2013-11-14 11:18:45   \n",
       "1  http://images.cocodataset.org/train2017/000000...  2013-11-14 11:38:44   \n",
       "2  http://images.cocodataset.org/train2017/000000...  2013-11-14 12:36:29   \n",
       "3  http://images.cocodataset.org/train2017/000000...  2013-11-14 13:02:53   \n",
       "4  http://images.cocodataset.org/train2017/000000...  2013-11-14 16:03:19   \n",
       "\n",
       "          file_name                                         flickr_url  \\\n",
       "0  000000391895.jpg  http://farm9.staticflickr.com/8186/8119368305_...   \n",
       "1  000000522418.jpg  http://farm1.staticflickr.com/1/127244861_ab0c...   \n",
       "2  000000184613.jpg  http://farm3.staticflickr.com/2169/2118578392_...   \n",
       "3  000000318219.jpg  http://farm5.staticflickr.com/4125/5094763076_...   \n",
       "4  000000554625.jpg  http://farm5.staticflickr.com/4086/5094162993_...   \n",
       "\n",
       "   height      id  license  width  \n",
       "0     360  391895        3    640  \n",
       "1     480  522418        4    640  \n",
       "2     336  184613        3    500  \n",
       "3     640  318219        3    556  \n",
       "4     640  554625        3    426  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgdf=pd.DataFrame(jsdict[\"images\"])\n",
    "imgdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An annotation table, in this case, we use \"bbox\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>bbox</th>\n",
       "      <th>category_id</th>\n",
       "      <th>id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>iscrowd</th>\n",
       "      <th>segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2765.14865</td>\n",
       "      <td>[199.84, 200.46, 77.71, 70.88]</td>\n",
       "      <td>58</td>\n",
       "      <td>156</td>\n",
       "      <td>558840</td>\n",
       "      <td>0</td>\n",
       "      <td>[[239.97, 260.24, 222.04, 270.49, 199.84, 253....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1545.42130</td>\n",
       "      <td>[234.22, 317.11, 149.39, 38.55]</td>\n",
       "      <td>58</td>\n",
       "      <td>509</td>\n",
       "      <td>200365</td>\n",
       "      <td>0</td>\n",
       "      <td>[[247.71, 354.7, 253.49, 346.99, 276.63, 337.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5607.66135</td>\n",
       "      <td>[239.48, 347.87, 160.0, 57.81]</td>\n",
       "      <td>58</td>\n",
       "      <td>603</td>\n",
       "      <td>200365</td>\n",
       "      <td>0</td>\n",
       "      <td>[[274.58, 405.68, 298.32, 405.68, 302.45, 402....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>[296.65, 388.33, 1.03, 0.0]</td>\n",
       "      <td>58</td>\n",
       "      <td>918</td>\n",
       "      <td>200365</td>\n",
       "      <td>0</td>\n",
       "      <td>[[296.65, 388.33, 296.65, 388.33, 297.68, 388....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800.41325</td>\n",
       "      <td>[251.87, 333.42, 125.94, 22.71]</td>\n",
       "      <td>58</td>\n",
       "      <td>1072</td>\n",
       "      <td>200365</td>\n",
       "      <td>0</td>\n",
       "      <td>[[251.87, 356.13, 260.13, 343.74, 300.39, 335....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         area                             bbox  category_id    id  image_id  \\\n",
       "0  2765.14865   [199.84, 200.46, 77.71, 70.88]           58   156    558840   \n",
       "1  1545.42130  [234.22, 317.11, 149.39, 38.55]           58   509    200365   \n",
       "2  5607.66135   [239.48, 347.87, 160.0, 57.81]           58   603    200365   \n",
       "3     0.00000      [296.65, 388.33, 1.03, 0.0]           58   918    200365   \n",
       "4   800.41325  [251.87, 333.42, 125.94, 22.71]           58  1072    200365   \n",
       "\n",
       "   iscrowd                                       segmentation  \n",
       "0        0  [[239.97, 260.24, 222.04, 270.49, 199.84, 253....  \n",
       "1        0  [[247.71, 354.7, 253.49, 346.99, 276.63, 337.3...  \n",
       "2        0  [[274.58, 405.68, 298.32, 405.68, 302.45, 402....  \n",
       "3        0  [[296.65, 388.33, 296.65, 388.33, 297.68, 388....  \n",
       "4        0  [[251.87, 356.13, 260.13, 343.74, 300.39, 335....  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df=pd.DataFrame(jsdict[\"annotations\"])\n",
    "ann_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A category table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urls = glob(IMG+\"/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/terminus/coco/train2017/000000184383.jpg',\n",
       " '/terminus/coco/train2017/000000038938.jpg',\n",
       " '/terminus/coco/train2017/000000029019.jpg',\n",
       " '/terminus/coco/train2017/000000256529.jpg',\n",
       " '/terminus/coco/train2017/000000427301.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the image id from image url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rdimg = np.random.choice(urls)\n",
    "def get_id(url):\n",
    "    return int(url.split(\"/\")[-1].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the bounding box data from annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bb(rdimg):\n",
    "    match = ann_df[ann_df[\"image_id\"]==get_id(rdimg)][[\"bbox\",\"category_id\"]]\n",
    "    return list(match[\"bbox\"]),list(match[\"category_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[323.6, 125.99, 79.47, 301.01],\n",
       "  [371.09, 74.94, 167.72, 257.36],\n",
       "  [176.41, 110.22, 107.27, 316.78],\n",
       "  [0.0, 189.03, 640.0, 172.72],\n",
       "  [3.95, 345.39, 92.12, 81.61],\n",
       "  [547.48, 272.28, 92.52, 153.58],\n",
       "  [429.22, 333.69, 113.63, 92.96],\n",
       "  [387.96, 390.18, 38.74, 36.82]],\n",
       " [1, 1, 1, 42, 62, 62, 62, 62])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bb(rdimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Picture boxes by loops into the picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(Image.open(rdimg))\n",
    "bbs,cids = get_bb(rdimg)\n",
    "for i in range(len(bbs)):\n",
    "    bb=bbs[i]\n",
    "    # format of the bb: x, y, width, height\n",
    "    rect = patches.Rectangle((bb[0],bb[1]),bb[2],bb[3],linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "    ax.add_patch(rect)\n",
    "    # format of bb \n",
    "    ax.text(bb[0],bb[1],idx2name[cids[i]],dict({\"color\":\"#ff0000\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig.savefig(\"bbtest.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You Only Look Once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "From the paper [You Only Look Once: Unified, Real-Time Object Detection](http://arxiv.org/abs/1506.02640)\n",
    "\n",
    "We divid the image to the grid boxes of size $S*S$\n",
    "\n",
    "In each grid cell, we predict $B$ bounding boxes \n",
    "\n",
    "Each $B$ we have 5 predictions $x, y, w, h$ and confidence, \n",
    "\n",
    "$x,y$ relative to the grid box.$w, h$ relative to the entire picture.\n",
    "\n",
    "Each grid cell, we predict class probability $Pr(Class_{i}|Object)$.\n",
    "\n",
    "Then **class specified** confidence scores, when at test time we shall calculate, are:\n",
    "\n",
    "$Pr(Class_{i}|Object)*Pr(Object)* IOU^{truth}_{pred}=Pr(Class_{i})* IOU^{truth}_{pred}$\n",
    "\n",
    "IOU: **Intersection Over Union**\n",
    "\n",
    "So the prediction are encoded in a tensor of size $S*S*(B*5+C)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO style with anchor box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get resized bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare bb data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data rows 860001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bbox</th>\n",
       "      <th>category_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>cate_id_oh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[260.4, 69.1, 88.66, 20.23]</td>\n",
       "      <td>9</td>\n",
       "      <td>504321</td>\n",
       "      <td>504321</td>\n",
       "      <td>000000504321.jpg</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[164.7, 39.54, 262.3, 560.54]</td>\n",
       "      <td>1</td>\n",
       "      <td>148551</td>\n",
       "      <td>148551</td>\n",
       "      <td>000000148551.jpg</td>\n",
       "      <td>640</td>\n",
       "      <td>427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[340.76, 4.43, 137.45, 113.11]</td>\n",
       "      <td>3</td>\n",
       "      <td>113326</td>\n",
       "      <td>113326</td>\n",
       "      <td>000000113326.jpg</td>\n",
       "      <td>640</td>\n",
       "      <td>480</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[152.3, 332.33, 80.71, 45.97]</td>\n",
       "      <td>8</td>\n",
       "      <td>216319</td>\n",
       "      <td>216319</td>\n",
       "      <td>000000216319.jpg</td>\n",
       "      <td>480</td>\n",
       "      <td>640</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[98.19, 138.09, 30.55, 102.78]</td>\n",
       "      <td>1</td>\n",
       "      <td>71986</td>\n",
       "      <td>71986</td>\n",
       "      <td>000000071986.jpg</td>\n",
       "      <td>375</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             bbox  category_id  image_id      id  \\\n",
       "0     [260.4, 69.1, 88.66, 20.23]            9    504321  504321   \n",
       "1   [164.7, 39.54, 262.3, 560.54]            1    148551  148551   \n",
       "2  [340.76, 4.43, 137.45, 113.11]            3    113326  113326   \n",
       "3   [152.3, 332.33, 80.71, 45.97]            8    216319  216319   \n",
       "4  [98.19, 138.09, 30.55, 102.78]            1     71986   71986   \n",
       "\n",
       "          file_name  height  width  cate_id_oh  \n",
       "0  000000504321.jpg     375    500           8  \n",
       "1  000000148551.jpg     640    427           0  \n",
       "2  000000113326.jpg     640    480           2  \n",
       "3  000000216319.jpg     480    640           7  \n",
       "4  000000071986.jpg     375    500           0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_data(imgdf,ann_df,shuffle=True):\n",
    "    \"\"\"\n",
    "    imgdf:\n",
    "    A dataframe about images, fields: \"id\",\"file_name\",\"height\",\"width\"\n",
    "    ann_df:\n",
    "    A dataframe about annotation, fields: \"image_id\",\"category_id\",\"bbox\",\n",
    "    The field \"bbox\" is a list of 4 values: x,y,height, width of the bounding box\n",
    "    \"\"\"\n",
    "    data_df=pd.merge(ann_df[[\"bbox\",\"category_id\",\"image_id\"]],\n",
    "                     imgdf[[\"id\",\"file_name\",\"height\",\"width\"]],\n",
    "                     left_on=\"image_id\",right_on=\"id\")\n",
    "    \n",
    "    data_df[\"cate_id_oh\"] = data_df[\"category_id\"].apply(lambda x:idx2id[x])\n",
    "    if shuffle:\n",
    "        data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
    "    print(\"total data rows\",len(data_df))\n",
    "    return data_df\n",
    "\n",
    "data_df = df_data(imgdf,ann_df)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Resize the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bbox_array = np.array(data_df.bbox.tolist())\n",
    "wh_array = data_df[[\"width\",\"height\"]].as_matrix()\n",
    "\n",
    "def re_calibrate(bbox_array,wh_array):\n",
    "    \"\"\"return the resized bbox array\"\"\"\n",
    "    bb_resized = (bbox_array/np.concatenate([wh_array,wh_array],axis=-1)) *SIZE\n",
    "    \n",
    "    true_bb = bb_resized/SCALE\n",
    "    # switch xy as left top conner to center point\n",
    "    true_bb[...,:2]=true_bb[...,:2]+true_bb[...,2:]/2\n",
    "    # Labels' Anchor positions on the grid map\n",
    "    grid_bbxy = np.floor(true_bb[...,:2])\n",
    "    return bb_resized,true_bb,grid_bbxy\n",
    "\n",
    "def find_best_anchors(true_bbwh):\n",
    "    iou_score = []\n",
    "    for b in range(BOX):\n",
    "        wh_anc = np.tile(ANC_ARR[b],[true_bbwh.shape[0],1])\n",
    "        true_area = true_bbwh.prod(axis=-1)\n",
    "        anc_area = wh_anc.prod(axis=-1)\n",
    "    \n",
    "        inter_area = np.min([wh_anc,true_bbwh],axis=0).prod(axis=-1)\n",
    "    \n",
    "        union_area = true_area + anc_area - inter_area\n",
    "        iou_score.append(inter_area/union_area)\n",
    "    best_anchor_idx = np.array(iou_score).T.argmax(axis=-1)\n",
    "    return best_anchor_idx\n",
    "\n",
    "bb_resized,true_bb,grid_bbxy = re_calibrate(bbox_array,wh_array)\n",
    "true_bbxy,true_bbwh = true_bb[...,:2],true_bb[...,2:]\n",
    "best_anchor_idx = find_best_anchors(true_bbwh)\n",
    "\n",
    "min_lbl = SCALE * 0.001\n",
    "\n",
    "data_df[\"true_bb_x\"],data_df[\"true_bb_y\"],data_df[\"true_bb_w\"],data_df[\"true_bb_h\"]=true_bb[:,0],true_bb[:,1],true_bb[:,2],true_bb[:,3]\n",
    "data_df[\"true_grid_x\"],data_df[\"true_grid_y\"]=grid_bbxy[:,0],grid_bbxy[:,1]\n",
    "\n",
    "# data_df[\"true_bb_x\"]=data_df[\"true_bb_x\"]-data_df[\"true_grid_x\"]\n",
    "# data_df[\"true_bb_y\"]=data_df[\"true_bb_y\"]-data_df[\"true_grid_y\"]\n",
    "\n",
    "data_df[\"best_anchor\"]=best_anchor_idx\n",
    "data_df_ = data_df[data_df[\"true_bb_w\"]>min_lbl]\n",
    "data_df_ = data_df_[data_df_[\"true_bb_h\"]>min_lbl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Index to onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reverse adjust funtion to get train labels\n",
    "\n",
    "* t to b\n",
    "\n",
    "$\\large b_{x}=\\sigma(t_{x})+c_{x}$\n",
    "\n",
    "$\\large b_{y}=\\sigma(t_{y})+c_{y}$\n",
    "\n",
    "$\\large b_{w}=p_{w}e^{w}$\n",
    "\n",
    "$\\large b_{h}=p_{h}e^{h}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* b to t\n",
    "\n",
    "$\\large t_{x}=-ln(\\frac{1}{b_{x}-c_{x}}-1)$\n",
    "\n",
    "$\\large t_{y}=-ln(\\frac{1}{b_{y}-c_{y}}-1)$\n",
    "\n",
    "$\\large t_{w}=ln(\\frac{b_{w}}{p_{w}})$\n",
    "\n",
    "$\\large t_{h}=ln(\\frac{b_{h}}{p_{h}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conv_model import dn121_conv\n",
    "\n",
    "dn121=dn121_conv(DN121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class dn_yolo(nn.Module):\n",
    "    def __init__(self,feat_extra,feat_in):\n",
    "        super(dn_yolo,self).__init__()\n",
    "        self.feat_in = feat_in\n",
    "        self.feat_extra=feat_extra\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(self.feat_in,feat_in,kernel_size=(3,3),stride=(1,1),padding=1,bias=False)\n",
    "        self.conv_2 = nn.Conv2d(self.feat_in,feat_in,kernel_size=(3,3),stride=(1,1),padding=1,bias=False)\n",
    "        self.conv_3 = nn.Conv2d(self.feat_in,VEC_LEN*BOX,kernel_size=(1,1),stride=(1,1),padding=0,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.feat_in)\n",
    "        self.bn2 = nn.BatchNorm2d(self.feat_in)\n",
    "        self.bn3 = nn.BatchNorm2d(self.feat_in)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.feat_extra(x)\n",
    "        \n",
    "        x = self.bn1(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv_3(x)\n",
    "        \n",
    "        # from: bs,channel, height, width\n",
    "        # to: bs, width, height, channel\n",
    "        x = x.permute([0,3,2,1]).contiguous().view(-1,FEAT_W,FEAT_H,BOX,VEC_LEN)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((HEIGHT,WIDTH)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([.5,.5,.5],[.5,.5,.5])\n",
    "                               ])\n",
    "trans_origin = transforms.Compose([transforms.Resize((HEIGHT,WIDTH)),\n",
    "                                transforms.ToTensor(),\n",
    "                               ])\n",
    "back2PIL = transforms.Compose([transforms.ToPILImage(mode=\"RGB\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange\n",
    "from datetime import datetime\n",
    "import os\n",
    "from p3self.matchbox import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data_Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = Data_Multi(data_df=data_df_,\n",
    "                       transform=transform,\n",
    "                       trans_origin=trans_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=Trainer(train_set,batch_size=16,print_on=5)\n",
    "model = dn_yolo(dn121,1024)\n",
    "from loss_ import yolo3_loss_on_t as yolo3_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = yolo3_loss(lbd_coord=1,\n",
    "                       lbd_obj=5,\n",
    "                       lbd_noobj=1,\n",
    "                       lbd_cls=1,\n",
    "                       testing=False,train_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    torch.cuda.empty_cache()\n",
    "    model.cuda()\n",
    "    loss_func.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "optimizer = Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def action(*args,**kwargs):\n",
    "    \"\"\"\n",
    "    y_s: label for scoring, because the y's bb has been transformed into t\n",
    "    \"\"\"\n",
    "    x,original, t_box, conf_, cls_, mask, cls_mask, b_box = args[0]\n",
    "    iteration=kwargs[\"ite\"]\n",
    "    # x,t_box, conf_, cls_, mask, cls_mask, b_box = Variable(x), Variable(t_box), Variable(conf_), Variable(cls_), Variable(mask), Variable(cls_mask), Variable(b_box)\n",
    "    if CUDA:\n",
    "        x,t_box, conf_, cls_, mask, cls_mask, b_box = x.cuda(),t_box.cuda(), conf_.cuda(), cls_.cuda(), mask.cuda(), cls_mask.cuda(), b_box.cuda()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y_ = model(x)\n",
    "    model.x=x\n",
    "    model.y_=y_\n",
    "    \n",
    "    loss,loss_x,loss_y,loss_w,loss_h,loss_obj,loss_noobj,loss_cls = loss_func(y_,t_box, conf_, cls_, mask, cls_mask, b_box)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if iteration%30==0:\n",
    "        y_pred = loss_func.t2b(y_)[0:1,...]\n",
    "        if CUDA:\n",
    "            y_pred = y_pred.cpu()\n",
    "        img = back2PIL(original[0])\n",
    "        printimg = plot_bb(img,data_to_df_bmark(y_pred))\n",
    "    return {\"loss\":loss.item(),\n",
    "            \"loss_x\":loss_x.item(),\n",
    "            \"loss_y\":loss_y.item(),\n",
    "            \"loss_w\":loss_w.item(),\n",
    "            \"loss_h\":loss_h.item(),\n",
    "            \"loss_obj\":loss_obj.item(),\n",
    "            \"loss_noobj\":loss_noobj.item(),\n",
    "            \"loss_cls\":loss_cls.item(),}\n",
    "\n",
    "trainer.action=action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/7330 [00:02<1:25:39,  1.43it/s]"
     ]
    }
   ],
   "source": [
    "trainer.train(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"yolo_v3.0.0.3.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"yolo_v3.0.0.3.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.80018615722656"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(10,10).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 10, 10, 5, 85])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}