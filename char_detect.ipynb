{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply YOLO style Model For OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An effectient one-shot deep detwork for OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some searching, I didn't find any dataset with image+character label+ single char level bounding boxã€‚\n",
    "\n",
    "So the most direct solution: Create a scene text detection data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from torch.utils.data import dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from constant import *\n",
    "from constant_char import *\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "from p3self.matchbox import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3566"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(IDX2CHARS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texted image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw \n",
    "import os\n",
    "from char_data import Make_Char,rd,rd_font,Make_Char_cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPERIMENT\t False\n",
      "TRAIN_CLS\t True\n",
      "REBUILD_DATA\t False\n",
      "annotation for classification:\t /data/forge/char_lbl_cn.csv\n",
      "annotation for all:\t /data/forge/char_lbl.csv\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"EXPERIMENT\\t\",EXPERIMENT)\n",
    "print(\"TRAIN_CLS\\t\",TRAIN_CLS)\n",
    "print(\"REBUILD_DATA\\t\",REBUILD_DATA)\n",
    "print(\"annotation for classification:\\t\",ANN_CLS)\n",
    "print(\"annotation for all:\\t\",ANN)\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Image with Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "import os\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    \n",
    "    os.system(\"rm %s*\"%(IMG))\n",
    "    mc = Make_Char(img_dir = IMG_EPT,forge_dir=IMG)\n",
    "    dl = DataLoader(mc,batch_size=4,shuffle=True)\n",
    "    mc_gen=iter(dl)\n",
    "\n",
    "    if EXPERIMENT:\n",
    "        t=trange(3)\n",
    "    else:\n",
    "        t=trange(len(dl))\n",
    "\n",
    "    for i in t:_ = next(mc_gen)\n",
    "    mc.df_dicts = list(d for d in mc.df_dicts if type(d)!= dict)\n",
    "    pd.concat(mc.df_dicts,axis=0).to_csv(ANN)\n",
    "    \n",
    "    if TRAIN_CLS:\n",
    "        os.system(\"rm %s*\"%(IMG_CLS))\n",
    "        mc2 = Make_Char_cn(img_dir = IMG_EPT,forge_dir=IMG_CLS)\n",
    "        dl2 = DataLoader(mc2,batch_size=4,shuffle=True)\n",
    "        mc_gen2=iter(dl2)\n",
    "\n",
    "        if EXPERIMENT:\n",
    "            t=trange(3)\n",
    "        else:\n",
    "            t=trange(len(dl2))\n",
    "\n",
    "        for i in t:_ = next(mc_gen2)\n",
    "        mc2.df_dicts = list(d for d in mc2.df_dicts if type(d)!= dict)\n",
    "        pd.concat(mc2.df_dicts,axis=0).to_csv(ANN_CLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_df = pd.read_csv(ANN)\n",
    "if TRAIN_CLS:ann_df2 = pd.read_csv(ANN_CLS)\n",
    "# ann_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[32, 0, 30, 35]',\n",
       "  '[256, 288, 27, 32]',\n",
       "  '[96, 96, 25, 25]',\n",
       "  '[0, 256, 16, 22]',\n",
       "  '[32, 160, 29, 28]',\n",
       "  '[256, 0, 19, 28]',\n",
       "  '[288, 256, 29, 31]',\n",
       "  '[0, 192, 40, 34]',\n",
       "  '[288, 160, 21, 26]',\n",
       "  '[192, 32, 15, 14]',\n",
       "  '[160, 32, 28, 29]',\n",
       "  '[64, 288, 27, 29]',\n",
       "  '[0, 32, 17, 20]',\n",
       "  '[0, 288, 22, 25]',\n",
       "  '[256, 192, 30, 38]',\n",
       "  '[224, 0, 28, 33]',\n",
       "  '[128, 0, 29, 33]',\n",
       "  '[32, 192, 23, 27]',\n",
       "  '[224, 32, 30, 43]',\n",
       "  '[32, 96, 18, 22]',\n",
       "  '[256, 224, 24, 29]',\n",
       "  '[64, 64, 20, 23]',\n",
       "  '[288, 96, 21, 24]',\n",
       "  '[128, 96, 33, 42]',\n",
       "  '[64, 192, 28, 29]',\n",
       "  '[128, 288, 17, 20]',\n",
       "  '[128, 128, 28, 28]',\n",
       "  '[160, 288, 28, 28]',\n",
       "  '[96, 64, 30, 35]',\n",
       "  '[160, 192, 24, 29]',\n",
       "  '[224, 160, 23, 23]',\n",
       "  '[192, 192, 26, 30]',\n",
       "  '[288, 192, 27, 26]',\n",
       "  '[192, 256, 24, 26]',\n",
       "  '[160, 256, 20, 26]',\n",
       "  '[224, 256, 15, 17]',\n",
       "  '[224, 128, 17, 19]',\n",
       "  '[0, 64, 15, 16]',\n",
       "  '[32, 256, 22, 25]',\n",
       "  '[32, 64, 16, 16]',\n",
       "  '[0, 96, 29, 35]',\n",
       "  '[288, 64, 33, 38]',\n",
       "  '[128, 224, 23, 40]',\n",
       "  '[0, 128, 23, 22]',\n",
       "  '[224, 64, 25, 32]',\n",
       "  '[128, 32, 16, 19]',\n",
       "  '[96, 32, 15, 24]',\n",
       "  '[64, 128, 24, 34]',\n",
       "  '[64, 0, 16, 19]',\n",
       "  '[288, 128, 22, 25]'],\n",
       " [2056,\n",
       "  199,\n",
       "  290,\n",
       "  528,\n",
       "  1944,\n",
       "  2936,\n",
       "  1062,\n",
       "  2645,\n",
       "  1711,\n",
       "  2457,\n",
       "  3457,\n",
       "  750,\n",
       "  1790,\n",
       "  323,\n",
       "  3014,\n",
       "  627,\n",
       "  151,\n",
       "  3005,\n",
       "  490,\n",
       "  1587,\n",
       "  2973,\n",
       "  2416,\n",
       "  3338,\n",
       "  1265,\n",
       "  2730,\n",
       "  1039,\n",
       "  3472,\n",
       "  732,\n",
       "  1727,\n",
       "  785,\n",
       "  450,\n",
       "  2196,\n",
       "  2693,\n",
       "  2396,\n",
       "  2879,\n",
       "  2754,\n",
       "  2606,\n",
       "  2730,\n",
       "  2088,\n",
       "  801,\n",
       "  3525,\n",
       "  2966,\n",
       "  2408,\n",
       "  2518,\n",
       "  1229,\n",
       "  2884,\n",
       "  1958,\n",
       "  1373,\n",
       "  1274,\n",
       "  1744])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = glob(IMG_CLS+\"/*\")\n",
    "\n",
    "rdimg = np.random.choice(urls)\n",
    "def get_id(url):\n",
    "    return url.split(\"/\")[-1]\n",
    "\n",
    "def get_bb(rdimg):\n",
    "    match = ann_df2[ann_df2[\"image_id\"]==get_id(rdimg)][[\"bbox\",\"category_id\"]]\n",
    "    return list(match[\"bbox\"]),list(match[\"category_id\"])\n",
    "\n",
    "get_bb(rdimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.text as text\n",
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "# msyh = matplotlib.font_manager.FontProperties(fname='/data/fonts_cn/msyh.ttf')\n",
    "\n",
    "# fig,ax = plt.subplots(1)\n",
    "# ax.imshow(Image.open(rdimg).resize((HEIGHT,WIDTH)))\n",
    "# bbs,cids = get_bb(rdimg)\n",
    "# # font_label = ImageFont.FreeTypeFont(\"/data/fonts_cn/msyh.ttf\", 5)\n",
    "# for i in range(len(bbs)):\n",
    "#     bb=eval(bbs[i])\n",
    "#     # format of the bb: x, y, width, height\n",
    "#     rect = patches.Rectangle((bb[0],bb[1]),bb[2],bb[3],linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "#     ax.add_patch(rect)\n",
    "#     # format of bb \n",
    "#     ax.text(bb[0],bb[1],idx2name[cids[i]],dict({\"color\":\"#ff0000\"}),fontproperties=msyh)\n",
    "#     # print(idx2name[cids[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_data(ann_df,shuffle=True):\n",
    "    \"\"\"\n",
    "    imgdf:\n",
    "    A dataframe about images, fields: \"id\",\"file_name\",\"height\",\"width\"\n",
    "    ann_df:\n",
    "    A dataframe about annotation, fields: \"image_id\",\"category_id\",\"bbox\",\n",
    "    The field \"bbox\" is a list of 4 values: x,y,height, width of the bounding box\n",
    "    \"\"\"\n",
    "    data_df=ann_df\n",
    "    \n",
    "    data_df[\"cate_id_oh\"] = data_df[\"category_id\"].apply(lambda x:idx2id[x])\n",
    "    data_df[\"bbox\"] = data_df[\"bbox\"].apply(lambda x:eval(x))\n",
    "    if shuffle:\n",
    "        data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
    "    print(\"total data rows\",len(data_df))\n",
    "    data_df[\"width\"] = data_df[\"category_id\"].apply(lambda x:WIDTH)\n",
    "    data_df[\"height\"] = data_df[\"category_id\"].apply(lambda x:HEIGHT)\n",
    "    return data_df\n",
    "\n",
    "def re_calibrate(bbox_array,wh_array):\n",
    "    \"\"\"return the resized bbox array\"\"\"\n",
    "    bb_resized = (bbox_array/np.concatenate([wh_array,wh_array],axis=-1)) *SIZE\n",
    "    \n",
    "    true_bb = bb_resized/SCALE\n",
    "    # switch xy as left top conner to center point\n",
    "    true_bb[...,:2]=true_bb[...,:2]+true_bb[...,2:]/2\n",
    "    # Labels' Anchor positions on the grid map\n",
    "    grid_bbxy = np.floor(true_bb[...,:2])\n",
    "    return bb_resized,true_bb,grid_bbxy\n",
    "\n",
    "def find_best_anchors(true_bbwh):\n",
    "    iou_score = []\n",
    "    for b in range(BOX):\n",
    "        wh_anc = np.tile(ANC_ARR[b],[true_bbwh.shape[0],1])\n",
    "        true_area = true_bbwh.prod(axis=-1)\n",
    "        anc_area = wh_anc.prod(axis=-1)\n",
    "    \n",
    "        inter_area = np.min([wh_anc,true_bbwh],axis=0).prod(axis=-1)\n",
    "    \n",
    "        union_area = true_area + anc_area - inter_area\n",
    "        iou_score.append(inter_area/union_area)\n",
    "    best_anchor_idx = np.array(iou_score).T.argmax(axis=-1)\n",
    "    return best_anchor_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load full data\n",
      "total data rows 2117164\n",
      "Full data loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"Load full data\")\n",
    "data_df = df_data(ann_df)\n",
    "\n",
    "bbox_array = np.array(data_df.bbox.tolist()).astype(np.float64)\n",
    "wh_array = data_df[[\"width\",\"height\"]].as_matrix().astype(np.float64)\n",
    "\n",
    "bb_resized,true_bb,grid_bbxy = re_calibrate(bbox_array,wh_array)\n",
    "true_bbxy,true_bbwh = true_bb[...,:2],true_bb[...,2:]\n",
    "best_anchor_idx = find_best_anchors(true_bbwh)\n",
    "\n",
    "min_lbl = SCALE * 0.001\n",
    "\n",
    "data_df[\"true_bb_x\"],data_df[\"true_bb_y\"],data_df[\"true_bb_w\"],data_df[\"true_bb_h\"]=true_bb[:,0],true_bb[:,1],true_bb[:,2],true_bb[:,3]\n",
    "data_df[\"true_grid_x\"],data_df[\"true_grid_y\"]=grid_bbxy[:,0],grid_bbxy[:,1]\n",
    "\n",
    "data_df[\"best_anchor\"]=best_anchor_idx\n",
    "data_df_ = data_df[data_df[\"true_bb_w\"]>min_lbl]\n",
    "data_df_ = data_df_[data_df_[\"true_bb_h\"]>min_lbl]\n",
    "data_df_[\"only_cls\"]=1 # train the full loss function\n",
    "print(\"Full data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading classification data\n",
      "total data rows 5914350\n",
      "Classification data loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if TRAIN_CLS:\n",
    "    print(\"Loading classification data\")\n",
    "    data_df2 = df_data(ann_df2)\n",
    "    data_df2.head()\n",
    "\n",
    "    bbox_array2 = np.array(data_df2.bbox.tolist()).astype(np.float64)\n",
    "    wh_array2 = data_df2[[\"width\",\"height\"]].as_matrix().astype(np.float64)\n",
    "\n",
    "    bb_resized2,true_bb2,grid_bbxy2 = re_calibrate(bbox_array2,wh_array2)\n",
    "    true_bbxy2,true_bbwh2 = true_bb2[...,:2],true_bb2[...,2:]\n",
    "    best_anchor_idx2 = find_best_anchors(true_bbwh2)\n",
    "\n",
    "    min_lbl2 = SCALE * 0.001\n",
    "\n",
    "    data_df2[\"true_bb_x\"],data_df2[\"true_bb_y\"],data_df2[\"true_bb_w\"],data_df2[\"true_bb_h\"]=true_bb2[:,0],true_bb2[:,1],true_bb2[:,2],true_bb2[:,3]\n",
    "    data_df2[\"true_grid_x\"],data_df2[\"true_grid_y\"]=grid_bbxy2[:,0],grid_bbxy2[:,1]\n",
    "\n",
    "    data_df2[\"best_anchor\"]=best_anchor_idx2\n",
    "    data_df_cls = data_df2[data_df2[\"true_bb_w\"]>min_lbl2]\n",
    "    data_df_cls = data_df_cls[data_df_cls[\"true_bb_h\"]>min_lbl2]\n",
    "\n",
    "    data_df_cls[\"only_cls\"]=0 # only train the classification part\n",
    "\n",
    "    # Mix and shuffle the \"train all loss\" and \"train classification only\"\n",
    "    data_df_ = pd.concat([data_df_,data_df_cls],axis=0).sample(frac=1.).reset_index()\n",
    "    print(\"Classification data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reverse adjust funtion to get train labels\n",
    "\n",
    "* t to b\n",
    "\n",
    "$\\large b_{x}=\\sigma(t_{x})+c_{x}$\n",
    "\n",
    "$\\large b_{y}=\\sigma(t_{y})+c_{y}$\n",
    "\n",
    "$\\large b_{w}=p_{w}e^{w}$\n",
    "\n",
    "$\\large b_{h}=p_{h}e^{h}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* b to t\n",
    "\n",
    "$\\large t_{x}=-ln(\\frac{1}{b_{x}-c_{x}}-1)$\n",
    "\n",
    "$\\large t_{y}=-ln(\\frac{1}{b_{y}-c_{y}}-1)$\n",
    "\n",
    "$\\large t_{w}=ln(\\frac{b_{w}}{p_{w}})$\n",
    "\n",
    "$\\large t_{h}=ln(\\frac{b_{h}}{p_{h}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading conv layers from /home/paperspace/.torch/models/dn121_4.pkl\n"
     ]
    }
   ],
   "source": [
    "from conv_model import dn121_conv\n",
    "print(\"loading conv layers from %s\"%(DN121))\n",
    "dn121=dn121_conv(DN121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dn_yolo(nn.Module):\n",
    "    def __init__(self,feat_extra,feat_in):\n",
    "        super(dn_yolo,self).__init__()\n",
    "        self.feat_in = feat_in\n",
    "        self.feat_extra=feat_extra\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(self.feat_in,feat_in,kernel_size=(3,3),stride=(1,1),padding=1,bias=False)\n",
    "        self.conv_2 = nn.Conv2d(self.feat_in,feat_in,kernel_size=(3,3),stride=(1,1),padding=1,bias=False)\n",
    "        self.conv_3 = nn.Conv2d(self.feat_in,VEC_LEN*BOX,kernel_size=(1,1),stride=(1,1),padding=0,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.feat_in)\n",
    "        self.bn2 = nn.BatchNorm2d(self.feat_in)\n",
    "        self.bn3 = nn.BatchNorm2d(self.feat_in)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.feat_extra(x)\n",
    "        \n",
    "        x = self.bn1(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv_3(x)\n",
    "        \n",
    "        # from: bs,channel, height, width\n",
    "        # to: bs, width, height, channel\n",
    "        x = x.permute([0,3,2,1]).contiguous().view(-1,FEAT_W,FEAT_H,BOX,VEC_LEN)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((HEIGHT,WIDTH)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([.5,.5,.5],[.5,.5,.5])\n",
    "                               ])\n",
    "trans_origin = transforms.Compose([transforms.Resize((HEIGHT,WIDTH)),\n",
    "                                transforms.ToTensor(),\n",
    "                               ])\n",
    "back2PIL = transforms.Compose([transforms.ToPILImage(mode=\"RGB\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data_Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Data_Multi(data_df=data_df_,\n",
    "                       train_cls=TRAIN_CLS,\n",
    "                       transform=transform,\n",
    "                       trans_origin=trans_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=Trainer(train_set,batch_size=16,print_on=5)\n",
    "model = dn_yolo(dn121,1024)\n",
    "if TRAIN_CLS:\n",
    "    from loss_ import yolo3_loss_both as yolo3_loss\n",
    "else:\n",
    "    from loss_ import yolo3_loss_on_t as yolo3_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function lambdas\n",
    "loss_func = yolo3_loss(lbd_coord=LBD_COORD,lbd_obj=LBD_OBJ,\n",
    "                       lbd_noobj=LBD_NOOBJ,lbd_cls=LBD_CLS,\n",
    "                       testing=False,train_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA:\t True\n",
      "loading model to cuda\n"
     ]
    }
   ],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "print(\"CUDA:\\t\",CUDA)\n",
    "if CUDA:\n",
    "    print(\"loading model to cuda\")\n",
    "    torch.cuda.empty_cache()\n",
    "    model.cuda()\n",
    "    loss_func.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "optimizer = Adam(model.parameters(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"%s.torch/models/char_0.1.pkl\"%(HOME)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(*args,**kwargs):\n",
    "    \"\"\"\n",
    "    y_s: label for scoring, because the y's bb has been transformed into t\n",
    "    \"\"\"\n",
    "    if TRAIN_CLS:\n",
    "        x,original, t_box, conf_, cls_, mask, b_box,only_cls = args[0]\n",
    "    else:\n",
    "        x,original, t_box, conf_, cls_, mask, b_box = args[0]\n",
    "    iteration=kwargs[\"ite\"]\n",
    "    # x,t_box, conf_, cls_, mask, cls_mask, b_box = Variable(x), Variable(t_box), Variable(conf_), Variable(cls_), Variable(mask), Variable(cls_mask), Variable(b_box)\n",
    "    if CUDA:\n",
    "        x,t_box, conf_, cls_, mask, b_box = x.cuda(),t_box.cuda(), conf_.cuda(), cls_.cuda(), mask.cuda(),  b_box.cuda()\n",
    "        if TRAIN_CLS:\n",
    "            only_cls = only_cls.cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y_ = model(x)\n",
    "    model.x,model.y_=x,y_\n",
    "    \n",
    "    # train class only\n",
    "    if TRAIN_CLS:\n",
    "        loss,loss_x,loss_y,loss_w,loss_h,loss_obj,loss_noobj,loss_cls = loss_func(y_,t_box, conf_, cls_, mask, b_box, only_cls)\n",
    "    else:\n",
    "        loss,loss_x,loss_y,loss_w,loss_h,loss_obj,loss_noobj,loss_cls = loss_func(y_,t_box, conf_, cls_, mask, b_box)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if iteration%30==0:\n",
    "        y_pred = loss_func.t2b(y_)[0:1,...]\n",
    "        if CUDA:\n",
    "            y_pred = y_pred.cpu()\n",
    "        img = back2PIL(original[0])\n",
    "        printimg = plot_bb(img,data_to_df_bmark(y_pred))\n",
    "        torch.save(model.state_dict(), \"%s.torch/models/char_0.1.pkl\"%(HOME))\n",
    "    return {\"loss\":loss.item(),\n",
    "            \"loss_x\":loss_x.item(),\n",
    "            \"loss_y\":loss_y.item(),\n",
    "            \"loss_w\":loss_w.item(),\n",
    "            \"loss_h\":loss_h.item(),\n",
    "            \"loss_obj\":loss_obj.item(),\n",
    "            \"loss_noobj\":loss_noobj.item(),\n",
    "            \"loss_cls\":loss_cls.item(),}\n",
    "\n",
    "trainer.action=action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/7393 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/7393 [00:17<36:19:38, 17.69s/it]\u001b[A\n",
      "  0%|          | 2/7393 [00:35<36:34:37, 17.82s/it]\u001b[A\n",
      "  0%|          | 3/7393 [00:53<36:22:38, 17.72s/it]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-40839d992a4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/p3self/matchbox.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, name, log_addr)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_log\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mkdir -p %s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_addr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/p3self/matchbox.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"iter\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/obj_detection/data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mimg_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_id\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_cls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise TypeError('Could not compare {typ} type with Series'\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 763\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    764\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
