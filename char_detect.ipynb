{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply YOLO style Model For OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An effectient one-shot deep detwork for OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some searching, I didn't find any dataset with image+character label+ single char level bounding box。\n",
    "\n",
    "So the most direct solution: Create a scene text detection data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from torch.utils.data import dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from constant import *\n",
    "from constant_char import *\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "from p3self.matchbox import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3566"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(IDX2CHARS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Texted image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw \n",
    "import os\n",
    "from char_data import Make_Char,rd,rd_font,Make_Char_cn\n",
    "\n",
    "# rg_n,rg_l,rg_u,rg_c,\n",
    "\n",
    "# fonts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Image with Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REBUILD_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "import os\n",
    "\n",
    "if REBUILD_DATA:\n",
    "    \n",
    "    os.system(\"rm %s*\"%(IMG))\n",
    "    mc = Make_Char(img_dir = IMG_EPT,forge_dir=IMG)\n",
    "    dl = DataLoader(mc,batch_size=4,shuffle=True)\n",
    "    mc_gen=iter(dl)\n",
    "\n",
    "    if EXPERIMENT:\n",
    "        t=trange(3)\n",
    "    else:\n",
    "        t=trange(len(dl))\n",
    "\n",
    "    for i in t:_ = next(mc_gen)\n",
    "    mc.df_dicts = list(d for d in mc.df_dicts if type(d)!= dict)\n",
    "    pd.concat(mc.df_dicts,axis=0).to_csv(ANN)\n",
    "    \n",
    "    if TRAIN_CLS:\n",
    "        os.system(\"rm %s*\"%(IMG_CLS))\n",
    "        mc2 = Make_Char_cn(img_dir = IMG_EPT,forge_dir=IMG_CLS)\n",
    "        dl2 = DataLoader(mc2,batch_size=4,shuffle=True)\n",
    "        mc_gen2=iter(dl2)\n",
    "\n",
    "        if EXPERIMENT:\n",
    "            t=trange(3)\n",
    "        else:\n",
    "            t=trange(len(dl2))\n",
    "\n",
    "        for i in t:_ = next(mc_gen2)\n",
    "        mc2.df_dicts = list(d for d in mc2.df_dicts if type(d)!= dict)\n",
    "        pd.concat(mc2.df_dicts,axis=0).to_csv(ANN_CLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/forge/char_lbl_cn.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN_CLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_df = pd.read_csv(ANN)\n",
    "if TRAIN_CLS:ann_df2 = pd.read_csv(ANN_CLS)\n",
    "# ann_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[32, 160, 28, 29]',\n",
       "  '[160, 0, 25, 27]',\n",
       "  '[192, 96, 29, 33]',\n",
       "  '[96, 128, 25, 27]',\n",
       "  '[160, 96, 27, 25]',\n",
       "  '[288, 128, 17, 20]',\n",
       "  '[288, 256, 20, 25]',\n",
       "  '[288, 96, 23, 22]',\n",
       "  '[128, 256, 31, 44]',\n",
       "  '[224, 128, 30, 29]',\n",
       "  '[192, 0, 20, 25]',\n",
       "  '[32, 224, 19, 21]',\n",
       "  '[0, 0, 24, 33]',\n",
       "  '[288, 224, 18, 30]',\n",
       "  '[0, 64, 21, 29]',\n",
       "  '[224, 32, 24, 23]',\n",
       "  '[64, 128, 30, 28]',\n",
       "  '[64, 96, 17, 18]',\n",
       "  '[192, 128, 18, 21]',\n",
       "  '[64, 192, 19, 19]',\n",
       "  '[96, 256, 15, 19]',\n",
       "  '[32, 64, 29, 28]',\n",
       "  '[160, 128, 29, 37]',\n",
       "  '[160, 256, 17, 19]',\n",
       "  '[256, 224, 15, 17]',\n",
       "  '[0, 192, 31, 37]',\n",
       "  '[160, 224, 20, 22]',\n",
       "  '[192, 224, 25, 33]',\n",
       "  '[160, 32, 18, 23]',\n",
       "  '[160, 160, 15, 15]',\n",
       "  '[160, 64, 25, 27]',\n",
       "  '[32, 32, 22, 27]',\n",
       "  '[96, 64, 26, 33]',\n",
       "  '[96, 192, 25, 28]',\n",
       "  '[0, 224, 18, 19]',\n",
       "  '[256, 64, 20, 26]',\n",
       "  '[0, 160, 15, 17]',\n",
       "  '[256, 160, 18, 24]',\n",
       "  '[192, 160, 27, 33]',\n",
       "  '[0, 128, 17, 19]',\n",
       "  '[64, 160, 28, 34]',\n",
       "  '[224, 224, 18, 21]',\n",
       "  '[192, 288, 14, 17]',\n",
       "  '[128, 0, 31, 42]',\n",
       "  '[256, 256, 26, 31]',\n",
       "  '[192, 64, 25, 28]',\n",
       "  '[32, 96, 24, 26]',\n",
       "  '[288, 0, 37, 38]',\n",
       "  '[0, 256, 16, 20]',\n",
       "  '[288, 160, 24, 29]'],\n",
       " [1418,\n",
       "  2567,\n",
       "  3415,\n",
       "  3379,\n",
       "  1606,\n",
       "  366,\n",
       "  2711,\n",
       "  3304,\n",
       "  1640,\n",
       "  2382,\n",
       "  2280,\n",
       "  2119,\n",
       "  2028,\n",
       "  1588,\n",
       "  2402,\n",
       "  1576,\n",
       "  2298,\n",
       "  651,\n",
       "  1622,\n",
       "  3343,\n",
       "  952,\n",
       "  105,\n",
       "  3065,\n",
       "  1018,\n",
       "  245,\n",
       "  2030,\n",
       "  3059,\n",
       "  2259,\n",
       "  1047,\n",
       "  1744,\n",
       "  1111,\n",
       "  1756,\n",
       "  1816,\n",
       "  2156,\n",
       "  852,\n",
       "  3395,\n",
       "  1441,\n",
       "  1622,\n",
       "  761,\n",
       "  2454,\n",
       "  1862,\n",
       "  123,\n",
       "  445,\n",
       "  2238,\n",
       "  1193,\n",
       "  3532,\n",
       "  3084,\n",
       "  2055,\n",
       "  3136,\n",
       "  3269])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = glob(IMG_CLS+\"/*\")\n",
    "\n",
    "rdimg = np.random.choice(urls)\n",
    "def get_id(url):\n",
    "    return url.split(\"/\")[-1]\n",
    "\n",
    "def get_bb(rdimg):\n",
    "    match = ann_df2[ann_df2[\"image_id\"]==get_id(rdimg)][[\"bbox\",\"category_id\"]]\n",
    "    return list(match[\"bbox\"]),list(match[\"category_id\"])\n",
    "\n",
    "get_bb(rdimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.text as text\n",
    "# %matplotlib inline\n",
    "import matplotlib\n",
    "\n",
    "# msyh = matplotlib.font_manager.FontProperties(fname='/data/fonts_cn/msyh.ttf')\n",
    "\n",
    "# fig,ax = plt.subplots(1)\n",
    "# ax.imshow(Image.open(rdimg).resize((HEIGHT,WIDTH)))\n",
    "# bbs,cids = get_bb(rdimg)\n",
    "# # font_label = ImageFont.FreeTypeFont(\"/data/fonts_cn/msyh.ttf\", 5)\n",
    "# for i in range(len(bbs)):\n",
    "#     bb=eval(bbs[i])\n",
    "#     # format of the bb: x, y, width, height\n",
    "#     rect = patches.Rectangle((bb[0],bb[1]),bb[2],bb[3],linewidth=1,edgecolor='r',facecolor='none')\n",
    "\n",
    "#     ax.add_patch(rect)\n",
    "#     # format of bb \n",
    "#     ax.text(bb[0],bb[1],idx2name[cids[i]],dict({\"color\":\"#ff0000\"}),fontproperties=msyh)\n",
    "#     # print(idx2name[cids[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data rows 2117164\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>bbox</th>\n",
       "      <th>category_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>image_id</th>\n",
       "      <th>cate_id_oh</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>[43, 86, 21, 55]</td>\n",
       "      <td>6</td>\n",
       "      <td>000000524557.jpg</td>\n",
       "      <td>000000524557.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>[73, 271, 12, 23]</td>\n",
       "      <td>1</td>\n",
       "      <td>000000456433.jpg</td>\n",
       "      <td>000000456433.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>[147, 195, 42, 46]</td>\n",
       "      <td>730</td>\n",
       "      <td>000000444409.jpg</td>\n",
       "      <td>000000444409.jpg</td>\n",
       "      <td>730</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[143, 240, 15, 30]</td>\n",
       "      <td>6</td>\n",
       "      <td>000000576457.jpg</td>\n",
       "      <td>000000576457.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[89, 80, 10, 32]</td>\n",
       "      <td>34</td>\n",
       "      <td>000000259576.jpg</td>\n",
       "      <td>000000259576.jpg</td>\n",
       "      <td>34</td>\n",
       "      <td>320</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                bbox  category_id         file_name  \\\n",
       "0           3    [43, 86, 21, 55]            6  000000524557.jpg   \n",
       "1           6   [73, 271, 12, 23]            1  000000456433.jpg   \n",
       "2          20  [147, 195, 42, 46]          730  000000444409.jpg   \n",
       "3           1  [143, 240, 15, 30]            6  000000576457.jpg   \n",
       "4           7    [89, 80, 10, 32]           34  000000259576.jpg   \n",
       "\n",
       "           image_id  cate_id_oh  width  height  \n",
       "0  000000524557.jpg           6    320     320  \n",
       "1  000000456433.jpg           1    320     320  \n",
       "2  000000444409.jpg         730    320     320  \n",
       "3  000000576457.jpg           6    320     320  \n",
       "4  000000259576.jpg          34    320     320  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def df_data(ann_df,shuffle=True):\n",
    "    \"\"\"\n",
    "    imgdf:\n",
    "    A dataframe about images, fields: \"id\",\"file_name\",\"height\",\"width\"\n",
    "    ann_df:\n",
    "    A dataframe about annotation, fields: \"image_id\",\"category_id\",\"bbox\",\n",
    "    The field \"bbox\" is a list of 4 values: x,y,height, width of the bounding box\n",
    "    \"\"\"\n",
    "    data_df=ann_df\n",
    "    \n",
    "    data_df[\"cate_id_oh\"] = data_df[\"category_id\"].apply(lambda x:idx2id[x])\n",
    "    data_df[\"bbox\"] = data_df[\"bbox\"].apply(lambda x:eval(x))\n",
    "    if shuffle:\n",
    "        data_df = data_df.sample(frac=1).reset_index(drop=True)\n",
    "    print(\"total data rows\",len(data_df))\n",
    "    data_df[\"width\"] = data_df[\"category_id\"].apply(lambda x:WIDTH)\n",
    "    data_df[\"height\"] = data_df[\"category_id\"].apply(lambda x:HEIGHT)\n",
    "    return data_df\n",
    "\n",
    "data_df = df_data(ann_df)\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_array = np.array(data_df.bbox.tolist()).astype(np.float64)\n",
    "wh_array = data_df[[\"width\",\"height\"]].as_matrix().astype(np.float64)\n",
    "\n",
    "def re_calibrate(bbox_array,wh_array):\n",
    "    \"\"\"return the resized bbox array\"\"\"\n",
    "    bb_resized = (bbox_array/np.concatenate([wh_array,wh_array],axis=-1)) *SIZE\n",
    "    \n",
    "    true_bb = bb_resized/SCALE\n",
    "    # switch xy as left top conner to center point\n",
    "    true_bb[...,:2]=true_bb[...,:2]+true_bb[...,2:]/2\n",
    "    # Labels' Anchor positions on the grid map\n",
    "    grid_bbxy = np.floor(true_bb[...,:2])\n",
    "    return bb_resized,true_bb,grid_bbxy\n",
    "\n",
    "def find_best_anchors(true_bbwh):\n",
    "    iou_score = []\n",
    "    for b in range(BOX):\n",
    "        wh_anc = np.tile(ANC_ARR[b],[true_bbwh.shape[0],1])\n",
    "        true_area = true_bbwh.prod(axis=-1)\n",
    "        anc_area = wh_anc.prod(axis=-1)\n",
    "    \n",
    "        inter_area = np.min([wh_anc,true_bbwh],axis=0).prod(axis=-1)\n",
    "    \n",
    "        union_area = true_area + anc_area - inter_area\n",
    "        iou_score.append(inter_area/union_area)\n",
    "    best_anchor_idx = np.array(iou_score).T.argmax(axis=-1)\n",
    "    return best_anchor_idx\n",
    "\n",
    "bb_resized,true_bb,grid_bbxy = re_calibrate(bbox_array,wh_array)\n",
    "true_bbxy,true_bbwh = true_bb[...,:2],true_bb[...,2:]\n",
    "best_anchor_idx = find_best_anchors(true_bbwh)\n",
    "\n",
    "min_lbl = SCALE * 0.001\n",
    "\n",
    "data_df[\"true_bb_x\"],data_df[\"true_bb_y\"],data_df[\"true_bb_w\"],data_df[\"true_bb_h\"]=true_bb[:,0],true_bb[:,1],true_bb[:,2],true_bb[:,3]\n",
    "data_df[\"true_grid_x\"],data_df[\"true_grid_y\"]=grid_bbxy[:,0],grid_bbxy[:,1]\n",
    "\n",
    "data_df[\"best_anchor\"]=best_anchor_idx\n",
    "data_df_ = data_df[data_df[\"true_bb_w\"]>min_lbl]\n",
    "data_df_ = data_df_[data_df_[\"true_bb_h\"]>min_lbl]\n",
    "data_df_[\"only_cls\"]=1 # train the full loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data rows 5914350\n"
     ]
    }
   ],
   "source": [
    "if TRAIN_CLS:\n",
    "    data_df2 = df_data(ann_df2)\n",
    "    data_df2.head()\n",
    "\n",
    "    bbox_array2 = np.array(data_df2.bbox.tolist()).astype(np.float64)\n",
    "    wh_array2 = data_df2[[\"width\",\"height\"]].as_matrix().astype(np.float64)\n",
    "\n",
    "    bb_resized2,true_bb2,grid_bbxy2 = re_calibrate(bbox_array2,wh_array2)\n",
    "    true_bbxy2,true_bbwh2 = true_bb2[...,:2],true_bb2[...,2:]\n",
    "    best_anchor_idx2 = find_best_anchors(true_bbwh2)\n",
    "\n",
    "    min_lbl2 = SCALE * 0.001\n",
    "\n",
    "    data_df2[\"true_bb_x\"],data_df2[\"true_bb_y\"],data_df2[\"true_bb_w\"],data_df2[\"true_bb_h\"]=true_bb2[:,0],true_bb2[:,1],true_bb2[:,2],true_bb2[:,3]\n",
    "    data_df2[\"true_grid_x\"],data_df2[\"true_grid_y\"]=grid_bbxy2[:,0],grid_bbxy2[:,1]\n",
    "\n",
    "    data_df2[\"best_anchor\"]=best_anchor_idx2\n",
    "    data_df_cls = data_df2[data_df2[\"true_bb_w\"]>min_lbl2]\n",
    "    data_df_cls = data_df_cls[data_df_cls[\"true_bb_h\"]>min_lbl2]\n",
    "\n",
    "    data_df_cls[\"only_cls\"]=0 # only train the classification part\n",
    "\n",
    "    # Mix and shuffle the \"train all loss\" and \"train classification only\"\n",
    "    data_df_ = pd.concat([data_df_,data_df_cls],axis=0).sample(frac=1.).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reverse adjust funtion to get train labels\n",
    "\n",
    "* t to b\n",
    "\n",
    "$\\large b_{x}=\\sigma(t_{x})+c_{x}$\n",
    "\n",
    "$\\large b_{y}=\\sigma(t_{y})+c_{y}$\n",
    "\n",
    "$\\large b_{w}=p_{w}e^{w}$\n",
    "\n",
    "$\\large b_{h}=p_{h}e^{h}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* b to t\n",
    "\n",
    "$\\large t_{x}=-ln(\\frac{1}{b_{x}-c_{x}}-1)$\n",
    "\n",
    "$\\large t_{y}=-ln(\\frac{1}{b_{y}-c_{y}}-1)$\n",
    "\n",
    "$\\large t_{w}=ln(\\frac{b_{w}}{p_{w}})$\n",
    "\n",
    "$\\large t_{h}=ln(\\frac{b_{h}}{p_{h}})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conv_model import dn121_conv\n",
    "\n",
    "dn121=dn121_conv(DN121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dn_yolo(nn.Module):\n",
    "    def __init__(self,feat_extra,feat_in):\n",
    "        super(dn_yolo,self).__init__()\n",
    "        self.feat_in = feat_in\n",
    "        self.feat_extra=feat_extra\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(self.feat_in,feat_in,kernel_size=(3,3),stride=(1,1),padding=1,bias=False)\n",
    "        self.conv_2 = nn.Conv2d(self.feat_in,feat_in,kernel_size=(3,3),stride=(1,1),padding=1,bias=False)\n",
    "        self.conv_3 = nn.Conv2d(self.feat_in,VEC_LEN*BOX,kernel_size=(1,1),stride=(1,1),padding=0,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.feat_in)\n",
    "        self.bn2 = nn.BatchNorm2d(self.feat_in)\n",
    "        self.bn3 = nn.BatchNorm2d(self.feat_in)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.feat_extra(x)\n",
    "        \n",
    "        x = self.bn1(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.conv_3(x)\n",
    "        \n",
    "        # from: bs,channel, height, width\n",
    "        # to: bs, width, height, channel\n",
    "        x = x.permute([0,3,2,1]).contiguous().view(-1,FEAT_W,FEAT_H,BOX,VEC_LEN)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((HEIGHT,WIDTH)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([.5,.5,.5],[.5,.5,.5])\n",
    "                               ])\n",
    "trans_origin = transforms.Compose([transforms.Resize((HEIGHT,WIDTH)),\n",
    "                                transforms.ToTensor(),\n",
    "                               ])\n",
    "back2PIL = transforms.Compose([transforms.ToPILImage(mode=\"RGB\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data_Multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = Data_Multi(data_df=data_df_,\n",
    "                       train_cls=TRAIN_CLS,\n",
    "                       transform=transform,\n",
    "                       trans_origin=trans_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=Trainer(train_set,batch_size=16,print_on=5)\n",
    "model = dn_yolo(dn121,1024)\n",
    "if TRAIN_CLS:\n",
    "    from loss_ import yolo3_loss_train_cls as yolo3_loss\n",
    "else:\n",
    "    from loss_ import yolo3_loss_on_t as yolo3_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function lambdas\n",
    "loss_func = yolo3_loss(lbd_coord=LBD_COORD,lbd_obj=LBD_OBJ,\n",
    "                       lbd_noobj=LBD_NOOBJ,lbd_cls=LBD_CLS,\n",
    "                       testing=False,train_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    torch.cuda.empty_cache()\n",
    "    model.cuda()\n",
    "    loss_func.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "optimizer = Adam(model.parameters(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"%s.torch/models/char_0.1.pkl\"%(HOME)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(*args,**kwargs):\n",
    "    \"\"\"\n",
    "    y_s: label for scoring, because the y's bb has been transformed into t\n",
    "    \"\"\"\n",
    "    if TRAIN_CLS:\n",
    "        x,original, t_box, conf_, cls_, mask, b_box,only_cls = args[0]\n",
    "    else:\n",
    "        x,original, t_box, conf_, cls_, mask, b_box = args[0]\n",
    "    iteration=kwargs[\"ite\"]\n",
    "    # x,t_box, conf_, cls_, mask, cls_mask, b_box = Variable(x), Variable(t_box), Variable(conf_), Variable(cls_), Variable(mask), Variable(cls_mask), Variable(b_box)\n",
    "    if CUDA:\n",
    "        x,t_box, conf_, cls_, mask, b_box = x.cuda(),t_box.cuda(), conf_.cuda(), cls_.cuda(), mask.cuda(),  b_box.cuda()\n",
    "        if TRAIN_CLS:\n",
    "            only_cls = only_cls.cuda()\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    y_ = model(x)\n",
    "    model.x,model.y_=x,y_\n",
    "    \n",
    "    # train class only\n",
    "    if TRAIN_CLS:\n",
    "        loss,loss_x,loss_y,loss_w,loss_h,loss_obj,loss_noobj,loss_cls = loss_func(y_,t_box, conf_, cls_, mask, b_box, only_cls)\n",
    "    else:\n",
    "        loss,loss_x,loss_y,loss_w,loss_h,loss_obj,loss_noobj,loss_cls = loss_func(y_,t_box, conf_, cls_, mask, b_box)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    if iteration%30==0:\n",
    "        y_pred = loss_func.t2b(y_)[0:1,...]\n",
    "        if CUDA:\n",
    "            y_pred = y_pred.cpu()\n",
    "        img = back2PIL(original[0])\n",
    "        printimg = plot_bb(img,data_to_df_bmark(y_pred))\n",
    "        torch.save(model.state_dict(), \"%s.torch/models/char_0.1.pkl\"%(HOME))\n",
    "    return {\"loss\":loss.item(),\n",
    "            \"loss_x\":loss_x.item(),\n",
    "            \"loss_y\":loss_y.item(),\n",
    "            \"loss_w\":loss_w.item(),\n",
    "            \"loss_h\":loss_h.item(),\n",
    "            \"loss_obj\":loss_obj.item(),\n",
    "            \"loss_noobj\":loss_noobj.item(),\n",
    "            \"loss_cls\":loss_cls.item(),}\n",
    "\n",
    "trainer.action=action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "⭐[ep_0_i_24]\tloss\t6339.712✨\tloss_cls\t5984.541✨\tloss_h\t44.891✨\tloss_noobj\t89.581✨\tloss_obj\t173.900✨\tloss_w\t38.174✨\tloss_x\t4.478✨\tloss_y\t4.146:   0%|          | 29/7393 [09:01<38:13:37, 18.69s/it]   "
     ]
    }
   ],
   "source": [
    "trainer.train(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
